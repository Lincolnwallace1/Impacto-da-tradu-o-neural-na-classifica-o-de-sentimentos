{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a75f0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\linco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\linco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import re\n",
    "from nltk import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import dl_translate as dlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb363ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load config for 'rabindralamsal/finetuned-bertweet-sentiment-analysis'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'rabindralamsal/finetuned-bertweet-sentiment-analysis' is the correct path to a directory containing a config.json file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\users\\linco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\configuration_utils.py:596\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 596\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[1;32mc:\\users\\linco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\utils\\hub.py:282\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[1;32m--> 282\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(url_or_filename):\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\linco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\utils\\hub.py:492\u001b[0m, in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m etag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 492\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    493\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistant resource does not have an ETag, we won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be able to reliably ensure reproducibility.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    494\u001b[0m     )\n\u001b[0;32m    495\u001b[0m \u001b[38;5;66;03m# In case of a redirect,\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# save an extra redirect on the request.get call,\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;66;03m# and ensure we download the exact atomic version even if it changed\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;66;03m# between the HEAD and the GET (unlikely, but hey).\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: Distant resource does not have an ETag, we won't be able to reliably ensure reproducibility.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, TFAutoModelForSequenceClassification\n\u001b[1;32m----> 3\u001b[0m tokenizerR \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrabindralamsal/finetuned-bertweet-sentiment-analysis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m modelR \u001b[38;5;241m=\u001b[39m TFAutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrabindralamsal/finetuned-bertweet-sentiment-analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\linco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:484\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m--> 484\u001b[0m         config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    485\u001b[0m             pretrained_model_name_or_path, trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    486\u001b[0m         )\n\u001b[0;32m    487\u001b[0m     config_tokenizer_class \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtokenizer_class\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n",
      "File \u001b[1;32mc:\\users\\linco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:652\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    650\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_or_path\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pretrained_model_name_or_path\n\u001b[0;32m    651\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 652\u001b[0m config_dict, _ \u001b[38;5;241m=\u001b[39m PretrainedConfig\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[1;32mc:\\users\\linco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\configuration_utils.py:548\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    546\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    547\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 548\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    550\u001b[0m \u001b[38;5;66;03m# That config file may point us toward another config file to use.\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfiguration_files\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n",
      "File \u001b[1;32mc:\\users\\linco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\configuration_utils.py:636\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    630\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt connect to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to load this model, couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find it in the cached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles and it looks like \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not the path to a directory containing a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{configuration_file}\u001b[39;00m\u001b[38;5;124m file.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCheckout your internet connection or see how to run the library in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffline mode at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    634\u001b[0m     )\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m--> 636\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load config for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    638\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    639\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    640\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfiguration_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    641\u001b[0m     )\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    644\u001b[0m     \u001b[38;5;66;03m# Load config dict\u001b[39;00m\n\u001b[0;32m    645\u001b[0m     config_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_dict_from_json_file(resolved_config_file)\n",
      "\u001b[1;31mOSError\u001b[0m: Can't load config for 'rabindralamsal/finetuned-bertweet-sentiment-analysis'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'rabindralamsal/finetuned-bertweet-sentiment-analysis' is the correct path to a directory containing a config.json file"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "  \n",
    "tokenizerR = AutoTokenizer.from_pretrained(\"rabindralamsal/finetuned-bertweet-sentiment-analysis\")\n",
    "\n",
    "modelR = TFAutoModelForSequenceClassification.from_pretrained(\"rabindralamsal/finetuned-bertweet-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e150b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I loved Star Wars so much!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a60eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"unicamp-dl/translation-pt-en-t5\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"unicamp-dl/translation-pt-en-t5\")\n",
    "pten_pipeline = pipeline('text2text-generation', model=model, tokenizer=tokenizer)\n",
    "mt = dlt.TranslationModel()  # Slow when you load it for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adff6713",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_tweet = \"The NEET exams show our Govt in a poor light: unresponsiveness to genuine concerns; admit cards not delivered to aspirants in time; failure to provide centres in towns they reside, thus requiring unnecessary & risky travels. What a disgrace to treat our #Covid warriors like this!\"\n",
    "#this tweet resides on Twitter with an identifier-1435793872588738560\n",
    "    \n",
    "input = tokenizerR.encode(example_tweet, return_tensors=\"tf\")\n",
    "output = modelR.predict(input)[0]\n",
    "prediction = tf.nn.softmax(output, axis=1).numpy()\n",
    "sentiment = np.argmax(prediction)\n",
    "    \n",
    "print(prediction)\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8b5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_portuguese = pd.read_csv(\"datasets/export_TweetSentBR.csv\")\n",
    "df_english = pd.read_csv(\"datasets/export_TweetSentEnglish.csv\")\n",
    "dataset = pd.read_csv(\"./datasetcompleto.csv\")\n",
    "completo = pd.read_csv(\"./TweetCompleto11k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e3ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "completo.drop(columns = ['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b102b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f796c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "completo['tweets_translater_unicamp'] = completo['tweets_translater_unicamp'].replace('','')\n",
    "completo['tweets_translater_face'] = completo['tweets_translater_face'].replace('\"','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7441e9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm not sure I'm going to do it, I'm going to do it, I'm going to do it, I'm going to do it, I'm going to do it, I'm going to do it.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completo['tweets_translater_face'][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "861c2ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remove = df_portuguese[df_portuguese['sentiment'] == '-']\n",
    "df_portuguese = df_portuguese.drop(df_remove.index)\n",
    "df_portuguese = df_portuguese.reset_index()\n",
    "df_portuguese = df_portuguese.drop(columns=['index'])\n",
    "df_portuguese['sentiment'] = df_portuguese['sentiment'].apply(lambda x: int(x))\n",
    "Tweet = df_portuguese['text']\n",
    "polarity = np.asarray(df_portuguese['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d06dcf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns = ['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17e17894",
   "metadata": {},
   "outputs": [],
   "source": [
    "completo = completo.dropna().reset_index().drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f6db168",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_portuguese['text'] = df_portuguese['text'].apply(remove_user)\n",
    "df_portuguese.drop(columns = ['id', 'id_twitter'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f21fc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_original</th>\n",
       "      <th>tweets_translater_unicamp</th>\n",
       "      <th>tweets_translater_face</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Que coisa linda! O Programa #encontro estava m...</td>\n",
       "      <td>The #encontro Program was showing a family tha...</td>\n",
       "      <td>What a beautiful thing! The #touch program was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Por mais #Encontro com as Irmãs Galvão, adorei...</td>\n",
       "      <td>I loved them.</td>\n",
       "      <td>For more I met with the Galvan Sisters, I love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr. CATRA  lançando sua nova música PPK CHORA ...</td>\n",
       "      <td>CATRA launching its new song PPK CHORA no k</td>\n",
       "      <td>Mr. CATRA releases his new song PPK CHORA on k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quem viu aquela lutadora modela barbuda tatuad...</td>\n",
       "      <td>#MasterChefBR</td>\n",
       "      <td>Who saw that fighter model tattooed? #MasterCh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tô passada com esse cara.... quanta merda pode...</td>\n",
       "      <td>I'm handled with this guy.... how mu\"</td>\n",
       "      <td>How much shit can come out of someone’s mouth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11511</th>\n",
       "      <td>a animação da filha da vanessa da mata é de se...</td>\n",
       "      <td>The animation of the daughter of vanessa da ma...</td>\n",
       "      <td>The animation of the daughter of the vanessa o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11512</th>\n",
       "      <td>eu ja to aqui pronto pro #MasterChefBR mas ain...</td>\n",
       "      <td>I'm already here ready for #MasterChefBR but\"</td>\n",
       "      <td>I'm ready to go here for #MasterChefBR but I'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11513</th>\n",
       "      <td>MALUCO! Uma coisa que eu não tenho coragem é e...</td>\n",
       "      <td>One thing I don't have the courage is this\"</td>\n",
       "      <td>One thing I don’t have the courage is that nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11514</th>\n",
       "      <td>#MaisVoce   está linda</td>\n",
       "      <td>#By You are beautiful #ByYou are beauti</td>\n",
       "      <td>#MaisVoce is beautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11515</th>\n",
       "      <td>Que orgulho de ti, ! #Encontro</td>\n",
       "      <td>What pride of you,! #I meet you</td>\n",
       "      <td>I am proud of you! #Meet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11516 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tweets_original  \\\n",
       "0      Que coisa linda! O Programa #encontro estava m...   \n",
       "1      Por mais #Encontro com as Irmãs Galvão, adorei...   \n",
       "2      Mr. CATRA  lançando sua nova música PPK CHORA ...   \n",
       "3      quem viu aquela lutadora modela barbuda tatuad...   \n",
       "4      Tô passada com esse cara.... quanta merda pode...   \n",
       "...                                                  ...   \n",
       "11511  a animação da filha da vanessa da mata é de se...   \n",
       "11512  eu ja to aqui pronto pro #MasterChefBR mas ain...   \n",
       "11513  MALUCO! Uma coisa que eu não tenho coragem é e...   \n",
       "11514                            #MaisVoce   está linda    \n",
       "11515                     Que orgulho de ti, ! #Encontro   \n",
       "\n",
       "                               tweets_translater_unicamp  \\\n",
       "0      The #encontro Program was showing a family tha...   \n",
       "1                                          I loved them.   \n",
       "2            CATRA launching its new song PPK CHORA no k   \n",
       "3                                          #MasterChefBR   \n",
       "4                  I'm handled with this guy.... how mu\"   \n",
       "...                                                  ...   \n",
       "11511  The animation of the daughter of vanessa da ma...   \n",
       "11512      I'm already here ready for #MasterChefBR but\"   \n",
       "11513        One thing I don't have the courage is this\"   \n",
       "11514            #By You are beautiful #ByYou are beauti   \n",
       "11515                    What pride of you,! #I meet you   \n",
       "\n",
       "                                  tweets_translater_face  \n",
       "0      What a beautiful thing! The #touch program was...  \n",
       "1      For more I met with the Galvan Sisters, I love...  \n",
       "2      Mr. CATRA releases his new song PPK CHORA on k...  \n",
       "3      Who saw that fighter model tattooed? #MasterCh...  \n",
       "4      How much shit can come out of someone’s mouth ...  \n",
       "...                                                  ...  \n",
       "11511  The animation of the daughter of the vanessa o...  \n",
       "11512  I'm ready to go here for #MasterChefBR but I'm...  \n",
       "11513  One thing I don’t have the courage is that nor...  \n",
       "11514                             #MaisVoce is beautiful  \n",
       "11515                           I am proud of you! #Meet  \n",
       "\n",
       "[11516 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce59ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english.drop(columns = ['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5f598c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrases</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The #encontro Program was showing a family tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I loved them.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CATRA launching its new song PPK CHORA no k</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#MasterChefBR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm handled with this guy.... how mu\"</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11528</th>\n",
       "      <td>I'm already here ready for #MasterChefBR but\"</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11529</th>\n",
       "      <td>One thing I don't have the courage is this\"</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11530</th>\n",
       "      <td>#By You are beautiful #ByYou are beauti</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11531</th>\n",
       "      <td>What pride of you,! #I meet you</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11532</th>\n",
       "      <td>People look at the biceps of this priest #Conv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11533 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 phrases  classification\n",
       "0      The #encontro Program was showing a family tha...               1\n",
       "1                                          I loved them.               1\n",
       "2            CATRA launching its new song PPK CHORA no k               1\n",
       "3                                          #MasterChefBR               0\n",
       "4                  I'm handled with this guy.... how mu\"              -1\n",
       "...                                                  ...             ...\n",
       "11528      I'm already here ready for #MasterChefBR but\"              -1\n",
       "11529        One thing I don't have the courage is this\"              -1\n",
       "11530            #By You are beautiful #ByYou are beauti               1\n",
       "11531                    What pride of you,! #I meet you               1\n",
       "11532  People look at the biceps of this priest #Conv...               1\n",
       "\n",
       "[11533 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b91a177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11533, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_portuguese.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16a2bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_X(frases):\n",
    "    lista = []\n",
    "    \n",
    "    for frase in frases:\n",
    "        lista.append(frase)\n",
    "        \n",
    "    return lista\n",
    "\n",
    "def pre_Y(number):\n",
    "    lista = []\n",
    "    \n",
    "    for numb in number:\n",
    "        lista.append(numb)\n",
    "    \n",
    "    return lista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "719331ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_array(frases):\n",
    "    \n",
    "    vocab = []\n",
    "    palavras = []\n",
    "    for frase in frases:\n",
    "        \n",
    "        text_array = remove_user(frase)\n",
    "        text_array = Tokenize(text_array)\n",
    "        text_array = text_array.split(' ')\n",
    "        for i in range(len(text_array)):\n",
    "            vocab.append(text_array[i])\n",
    "    \n",
    "    \n",
    "        \n",
    "    return vocab\n",
    "\n",
    "def Tokenize(f):     ## Pre-processando a frase\n",
    "    \n",
    "    ## Colocando em minusculo\n",
    "    ## Retirando a pontuaçao\n",
    "    ## Retirando as StopWords\n",
    "    \n",
    "    f = f.lower().replace('\\n', '').replace('-','').replace('#','').replace('.','').replace(',','').replace('!','').replace('r\\n','').replace('  ','')\n",
    "    token = RegexpTokenizer(r\"\\w+\")\n",
    "    f = token.tokenize(f)\n",
    "    \n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    \n",
    "    new_word = [word for word in f if not word in stop_words]\n",
    "    \n",
    "    return ' '.join(new_word)\n",
    "\n",
    "def remove_user(frase):\n",
    "\n",
    "    return re.sub('@\\w+','',frase)\n",
    "\n",
    "def translater_phrases(frase):\n",
    "    translater = pten_pipeline(frase)\n",
    "    translater = str(translater).strip('[{}]')\n",
    "    translater = translater[19:]\n",
    "    translater = translater.strip(\"''\")\n",
    "    \n",
    "    return translater\n",
    "\n",
    "def translater_frases(frase):\n",
    "    text_hi = frase\n",
    "    translater = mt.translate(text_hi, source=dlt.lang.PORTUGUESE, target=dlt.lang.ENGLISH)\n",
    "    \n",
    "    return translater\n",
    "\n",
    "def new_classifier(frase):\n",
    "    input = tokenizerR.encode(frase, return_tensors=\"tf\")\n",
    "    output = modelR.predict(input)[0]\n",
    "    prediction = tf.nn.softmax(output, axis=1).numpy()\n",
    "    sentiment = np.argmax(prediction)\n",
    "    \n",
    "    return sentiment \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b0fb0bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tweet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Tweet \u001b[38;5;241m=\u001b[39m \u001b[43mTweet\u001b[49m\u001b[38;5;241m.\u001b[39mapply(remove_user)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Tweet' is not defined"
     ]
    }
   ],
   "source": [
    "Tweet = Tweet.apply(remove_user)\n",
    "# Tweet_preprocessed = Tweet.apply(Tokenize)\n",
    "\n",
    "# count_vect = CountVectorizer()\n",
    "# X_train = count_vect.fit_transform(Tweet_preprocessed)\n",
    "\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_train_transform = tfidf_transformer.fit_transform(X_train) # Aplicando o TF-IDF\n",
    "\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X_train_transform, polarity, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1ef5986",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_in_English = pd.DataFrame(data = {'tweets_original': df_portuguese['text'][8000:11532], 'tweets_translater_unicamp': df_english['phrases'][8000:11532],'tweets_translater_face': df_portuguese['text'][8000:11532].apply(translater_frases)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6578d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_in_English.to_csv('tweets11000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8aec7626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_original</th>\n",
       "      <th>tweets_translater_unicamp</th>\n",
       "      <th>tweets_translater_face</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Que coisa linda! O Programa #encontro estava m...</td>\n",
       "      <td>The #encontro Program was showing a family tha...</td>\n",
       "      <td>What a beautiful thing! The #touch program was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Por mais #Encontro com as Irmãs Galvão, adorei...</td>\n",
       "      <td>I loved them.</td>\n",
       "      <td>For more I met with the Galvan Sisters, I love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr. CATRA  lançando sua nova música PPK CHORA ...</td>\n",
       "      <td>CATRA launching its new song PPK CHORA no k</td>\n",
       "      <td>Mr. CATRA releases his new song PPK CHORA on k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quem viu aquela lutadora modela barbuda tatuad...</td>\n",
       "      <td>#MasterChefBR</td>\n",
       "      <td>Who saw that fighter model tattooed? #MasterCh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tô passada com esse cara.... quanta merda pode...</td>\n",
       "      <td>I'm handled with this guy.... how mu\"</td>\n",
       "      <td>How much shit can come out of someone’s mouth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>#VideoShowAoVivo Kkkk ahhh eu morro com esse V...</td>\n",
       "      <td>I love this guy!</td>\n",
       "      <td>#VideoShowAoLive Kkkk ahhh I die with this Sum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Até o Padre Fábio de Melo cantando Trem Bala, ...</td>\n",
       "      <td>Even Father Fábio de Melo singing Trem Bala, i...</td>\n",
       "      <td>Even the Fabius Father of Melo singing Trem Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>#MaisVocê minha irmã calça 34 e compra sapato ...</td>\n",
       "      <td>Never had difficulty in finding this number of...</td>\n",
       "      <td>You my sister shoes 34 and buy shoes in any st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Iris tão fofa e linda 😻😻💙 #EDeCasa</td>\n",
       "      <td>Iris so fool and beautiful Iris  #EDeCasa</td>\n",
       "      <td>Iris so foolish and beautiful 🏻 #EDeCasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>#MaisVoce O FGTS não é descontado do funcionár...</td>\n",
       "      <td>The obligation is only of the company, which must</td>\n",
       "      <td>#MaisVoce The FGTS is not discounted from the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       tweets_original  \\\n",
       "0    Que coisa linda! O Programa #encontro estava m...   \n",
       "1    Por mais #Encontro com as Irmãs Galvão, adorei...   \n",
       "2    Mr. CATRA  lançando sua nova música PPK CHORA ...   \n",
       "3    quem viu aquela lutadora modela barbuda tatuad...   \n",
       "4    Tô passada com esse cara.... quanta merda pode...   \n",
       "..                                                 ...   \n",
       "495  #VideoShowAoVivo Kkkk ahhh eu morro com esse V...   \n",
       "496  Até o Padre Fábio de Melo cantando Trem Bala, ...   \n",
       "497  #MaisVocê minha irmã calça 34 e compra sapato ...   \n",
       "498                 Iris tão fofa e linda 😻😻💙 #EDeCasa   \n",
       "499  #MaisVoce O FGTS não é descontado do funcionár...   \n",
       "\n",
       "                             tweets_translater_unicamp  \\\n",
       "0    The #encontro Program was showing a family tha...   \n",
       "1                                        I loved them.   \n",
       "2          CATRA launching its new song PPK CHORA no k   \n",
       "3                                        #MasterChefBR   \n",
       "4                I'm handled with this guy.... how mu\"   \n",
       "..                                                 ...   \n",
       "495                                   I love this guy!   \n",
       "496  Even Father Fábio de Melo singing Trem Bala, i...   \n",
       "497  Never had difficulty in finding this number of...   \n",
       "498          Iris so fool and beautiful Iris  #EDeCasa   \n",
       "499  The obligation is only of the company, which must   \n",
       "\n",
       "                                tweets_translater_face  \n",
       "0    What a beautiful thing! The #touch program was...  \n",
       "1    For more I met with the Galvan Sisters, I love...  \n",
       "2    Mr. CATRA releases his new song PPK CHORA on k...  \n",
       "3    Who saw that fighter model tattooed? #MasterCh...  \n",
       "4    How much shit can come out of someone’s mouth ...  \n",
       "..                                                 ...  \n",
       "495  #VideoShowAoLive Kkkk ahhh I die with this Sum...  \n",
       "496  Even the Fabius Father of Melo singing Trem Ba...  \n",
       "497  You my sister shoes 34 and buy shoes in any st...  \n",
       "498           Iris so foolish and beautiful 🏻 #EDeCasa  \n",
       "499  #MaisVoce The FGTS is not discounted from the ...  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweets_in_English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fd9cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificacoes = pd.DataFrame(data = {'origem_portugues': df_portuguese['sentiment'], \n",
    "                                      'classificação_hug_com_unicamp_translater': completo['tweets_translater_unicamp'].apply(classifier),\n",
    "                                      'classificação_rabin_com_unicamp_translater': completo['tweets_translater_unicamp'].apply(new_classifier),\n",
    "                                      'classificação_hug_com_face_translater': completo['tweets_translater_face'].apply(classifier)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78693ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "origem_portugues                               0\n",
       "classificação_hug_com_unicamp_translater      17\n",
       "classificação_rabin_com_unicamp_translater    17\n",
       "classificação_hug_com_face_translater         17\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificacoes.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d386a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificacoes = classificacoes.dropna().reset_index().drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aba0ae45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origem_portugues</th>\n",
       "      <th>classificação_hug_com_unicamp_translater</th>\n",
       "      <th>classificação_rabin_com_unicamp_translater</th>\n",
       "      <th>classificação_hug_com_face_translater</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.978637635707...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.999819815158...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.999877452850...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.999851465225...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.993814468383...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.977949678897...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.983937680721...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.994238138198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.977942943572...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.999268591403...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11511</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.854824185371...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.999161243438...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11512</th>\n",
       "      <td>-1</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.973548531532...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.999184668064...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11513</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.999200165271...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'label': 'NEGATIVE', 'score': 0.998830497264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11514</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.999661445617...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.999835968017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11515</th>\n",
       "      <td>-1</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.999851465225...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[{'label': 'POSITIVE', 'score': 0.999861836433...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11516 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       origem_portugues           classificação_hug_com_unicamp_translater  \\\n",
       "0                     1  [{'label': 'NEGATIVE', 'score': 0.978637635707...   \n",
       "1                     1  [{'label': 'POSITIVE', 'score': 0.999877452850...   \n",
       "2                     1  [{'label': 'POSITIVE', 'score': 0.993814468383...   \n",
       "3                     0  [{'label': 'POSITIVE', 'score': 0.983937680721...   \n",
       "4                    -1  [{'label': 'NEGATIVE', 'score': 0.977942943572...   \n",
       "...                 ...                                                ...   \n",
       "11511                 0  [{'label': 'NEGATIVE', 'score': 0.854824185371...   \n",
       "11512                -1  [{'label': 'NEGATIVE', 'score': 0.973548531532...   \n",
       "11513                 1  [{'label': 'NEGATIVE', 'score': 0.999200165271...   \n",
       "11514                 0  [{'label': 'POSITIVE', 'score': 0.999661445617...   \n",
       "11515                -1  [{'label': 'POSITIVE', 'score': 0.999851465225...   \n",
       "\n",
       "       classificação_rabin_com_unicamp_translater  \\\n",
       "0                                             1.0   \n",
       "1                                             2.0   \n",
       "2                                             1.0   \n",
       "3                                             1.0   \n",
       "4                                             1.0   \n",
       "...                                           ...   \n",
       "11511                                         1.0   \n",
       "11512                                         1.0   \n",
       "11513                                         0.0   \n",
       "11514                                         2.0   \n",
       "11515                                         2.0   \n",
       "\n",
       "                   classificação_hug_com_face_translater  \n",
       "0      [{'label': 'POSITIVE', 'score': 0.999819815158...  \n",
       "1      [{'label': 'POSITIVE', 'score': 0.999851465225...  \n",
       "2      [{'label': 'NEGATIVE', 'score': 0.977949678897...  \n",
       "3      [{'label': 'NEGATIVE', 'score': 0.994238138198...  \n",
       "4      [{'label': 'NEGATIVE', 'score': 0.999268591403...  \n",
       "...                                                  ...  \n",
       "11511  [{'label': 'POSITIVE', 'score': 0.999161243438...  \n",
       "11512  [{'label': 'NEGATIVE', 'score': 0.999184668064...  \n",
       "11513  [{'label': 'NEGATIVE', 'score': 0.998830497264...  \n",
       "11514  [{'label': 'POSITIVE', 'score': 0.999835968017...  \n",
       "11515  [{'label': 'POSITIVE', 'score': 0.999861836433...  \n",
       "\n",
       "[11516 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea0eb708",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificacoes['classificação_hug_com_unicamp_translater'] = classificacoes['classificação_hug_com_unicamp_translater'].apply(lambda x: x[0]['label'])\n",
    "classificacoes['classificação_hug_com_face_translater'] = classificacoes['classificação_hug_com_face_translater'].apply(lambda x: x[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7da1f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificacoes['classificação_hug_com_unicamp_translater'] = classificacoes['classificação_hug_com_unicamp_translater'].replace('POSITIVE', 1).replace('NEGATIVE',-1)\n",
    "classificacoes['classificação_hug_com_face_translater'] = classificacoes['classificação_hug_com_face_translater'].replace('POSITIVE', 1).replace('NEGATIVE',-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b2284de",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificacoes['classificação_rabin_com_unicamp_translater'] = classificacoes['classificação_rabin_com_unicamp_translater'].replace(0, -1).replace(1,0).replace(2,1)\n",
    "# classificacoes['classificação_rabin_face'] = classificacoes['classificação_rabin_face'].replace(0, -1).replace(1,0).replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a0bfc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origem_portugues</th>\n",
       "      <th>classificação_hug_com_unicamp_translater</th>\n",
       "      <th>classificação_rabin_com_unicamp_translater</th>\n",
       "      <th>classificação_hug_com_face_translater</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11511</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11512</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11513</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11514</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11515</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11516 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       origem_portugues  classificação_hug_com_unicamp_translater  \\\n",
       "0                     1                                        -1   \n",
       "1                     1                                         1   \n",
       "2                     1                                         1   \n",
       "3                     0                                         1   \n",
       "4                    -1                                        -1   \n",
       "...                 ...                                       ...   \n",
       "11511                 0                                        -1   \n",
       "11512                -1                                        -1   \n",
       "11513                 1                                        -1   \n",
       "11514                 0                                         1   \n",
       "11515                -1                                         1   \n",
       "\n",
       "       classificação_rabin_com_unicamp_translater  \\\n",
       "0                                             0.0   \n",
       "1                                             1.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "...                                           ...   \n",
       "11511                                         0.0   \n",
       "11512                                         0.0   \n",
       "11513                                        -1.0   \n",
       "11514                                         1.0   \n",
       "11515                                         1.0   \n",
       "\n",
       "       classificação_hug_com_face_translater  \n",
       "0                                          1  \n",
       "1                                          1  \n",
       "2                                         -1  \n",
       "3                                         -1  \n",
       "4                                         -1  \n",
       "...                                      ...  \n",
       "11511                                      1  \n",
       "11512                                     -1  \n",
       "11513                                     -1  \n",
       "11514                                      1  \n",
       "11515                                      1  \n",
       "\n",
       "[11516 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655aa45e",
   "metadata": {},
   "source": [
    "## Acuracia da origem com classificador do huggingface e traduzido com o tradutor da unicamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fafae750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.368617575547065"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soma = 0\n",
    "for i in range (len(classificacoes)):\n",
    "    if(int(classificacoes['origem_portugues'][i]) == int(classificacoes['classificação_hug_com_unicamp_translater'][i])):\n",
    "        soma+=1\n",
    "\n",
    "soma/len(classificacoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680efd9",
   "metadata": {},
   "source": [
    "## Acuracia da origem com classificador do rabin e traduzido com o tradutor da unicamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c28cf363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3109586662035429"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soma = 0\n",
    "for i in range (len(classificacoes)):\n",
    "    if(int(classificacoes['origem_portugues'][i]) == int(classificacoes['classificação_rabin_com_unicamp_translater'][i])):\n",
    "        soma+=1\n",
    "\n",
    "soma/len(classificacoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5041356",
   "metadata": {},
   "source": [
    "## Acuracia da origem com classificador do huggingface e traduzido com o tradutor da m2m100 ou face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "483493dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37816950329975685"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soma = 0\n",
    "for i in range (len(classificacoes)):\n",
    "    if(int(classificacoes['origem_portugues'][i]) == int(classificacoes['classificação_hug_com_face_translater'][i])):\n",
    "        soma+=1\n",
    "\n",
    "soma/len(classificacoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ba6a2a",
   "metadata": {},
   "source": [
    "## Acuracia da origem com classificador do rabin e traduzido com o tradutor da m2m100 ou face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "76830d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soma = 0\n",
    "for i in range (len(classificacoes)):\n",
    "    if(int(classificacoes['origem_portugues'][i]) == int(classificacoes['classificação_rabin_face'][i])):\n",
    "        soma+=1\n",
    "\n",
    "soma/len(classificacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ec282b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
