{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a75f0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\linco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\linco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import re\n",
    "from nltk import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import dl_translate as dlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cb363ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "  \n",
    "tokenizerR = AutoTokenizer.from_pretrained(\"rabindralamsal/finetuned-bertweet-sentiment-analysis\")\n",
    "\n",
    "modelR = TFAutoModelForSequenceClassification.from_pretrained(\"rabindralamsal/finetuned-bertweet-sentiment-analysis\", from_pt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adff6713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97267216 0.02368472 0.00364307]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "example_tweet = \"The NEET exams show our Govt in a poor light: unresponsiveness to genuine concerns; admit cards not delivered to aspirants in time; failure to provide centres in towns they reside, thus requiring unnecessary & risky travels. What a disgrace to treat our #Covid warriors like this!\"\n",
    "#this tweet resides on Twitter with an identifier-1435793872588738560\n",
    "    \n",
    "input = tokenizer.encode(example_tweet, return_tensors=\"tf\")\n",
    "output = model.predict(input)[0]\n",
    "prediction = tf.nn.softmax(output, axis=1).numpy()\n",
    "sentiment = np.argmax(prediction)\n",
    "    \n",
    "print(prediction)\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1a60eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"unicamp-dl/translation-pt-en-t5\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"unicamp-dl/translation-pt-en-t5\")\n",
    "pten_pipeline = pipeline('text2text-generation', model=model, tokenizer=tokenizer)\n",
    "mt = dlt.TranslationModel()  # Slow when you load it for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dff1e41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.999840259552002}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I loved Star Wars so much!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc8b5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_portuguese = pd.read_csv(\"datasets/export_TweetSentBR.csv\")\n",
    "df_english = pd.read_csv(\"datasets/export_TweetSentEnglish.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "861c2ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remove = df_portuguese[df_portuguese['sentiment'] == '-']\n",
    "df_portuguese = df_portuguese.drop(df_remove.index)\n",
    "df_portuguese = df_portuguese.reset_index()\n",
    "df_portuguese = df_portuguese.drop(columns=['index'])\n",
    "df_portuguese['sentiment'] = df_portuguese['sentiment'].apply(lambda x: int(x))\n",
    "Tweet = df_portuguese['text']\n",
    "polarity = np.asarray(df_portuguese['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13699adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets_in_English = pd.DataFrame( data = {'phrases': Tweets_in_Portuguese['frases'].apply(translater_phrases), 'classification': polarity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "921275ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets_in_Portuguese = pd.DataFrame( data = {'frases': Tweet ,'classificacao' : polarity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f6db168",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_portuguese['text'] = df_portuguese['text'].apply(remove_user)\n",
    "df_portuguese.drop(columns = ['id', 'id_twitter'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce59ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english.drop(columns = ['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5f598c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrases</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The #encontro Program was showing a family tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I loved them.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CATRA launching its new song PPK CHORA no k</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#MasterChefBR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm handled with this guy.... how mu\"</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11528</th>\n",
       "      <td>I'm already here ready for #MasterChefBR but\"</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11529</th>\n",
       "      <td>One thing I don't have the courage is this\"</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11530</th>\n",
       "      <td>#By You are beautiful #ByYou are beauti</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11531</th>\n",
       "      <td>What pride of you,! #I meet you</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11532</th>\n",
       "      <td>People look at the biceps of this priest #Conv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11533 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 phrases  classification\n",
       "0      The #encontro Program was showing a family tha...               1\n",
       "1                                          I loved them.               1\n",
       "2            CATRA launching its new song PPK CHORA no k               1\n",
       "3                                          #MasterChefBR               0\n",
       "4                  I'm handled with this guy.... how mu\"              -1\n",
       "...                                                  ...             ...\n",
       "11528      I'm already here ready for #MasterChefBR but\"              -1\n",
       "11529        One thing I don't have the courage is this\"              -1\n",
       "11530            #By You are beautiful #ByYou are beauti               1\n",
       "11531                    What pride of you,! #I meet you               1\n",
       "11532  People look at the biceps of this priest #Conv...               1\n",
       "\n",
       "[11533 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b91a177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Que coisa linda! O Programa #encontro estava m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Por mais #Encontro com as Irmãs Galvão, adorei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr. CATRA  lançando sua nova música PPK CHORA ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quem viu aquela lutadora modela barbuda tatuad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tô passada com esse cara.... quanta merda pode...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11528</th>\n",
       "      <td>eu ja to aqui pronto pro #MasterChefBR mas ain...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11529</th>\n",
       "      <td>MALUCO! Uma coisa que eu não tenho coragem é e...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11530</th>\n",
       "      <td>#MaisVoce   está linda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11531</th>\n",
       "      <td>Que orgulho de ti, ! #Encontro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11532</th>\n",
       "      <td>Gente olha o bíceps desse padre #ConversaComBial</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11533 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment\n",
       "0      Que coisa linda! O Programa #encontro estava m...          1\n",
       "1      Por mais #Encontro com as Irmãs Galvão, adorei...          1\n",
       "2      Mr. CATRA  lançando sua nova música PPK CHORA ...          1\n",
       "3      quem viu aquela lutadora modela barbuda tatuad...          0\n",
       "4      Tô passada com esse cara.... quanta merda pode...         -1\n",
       "...                                                  ...        ...\n",
       "11528  eu ja to aqui pronto pro #MasterChefBR mas ain...         -1\n",
       "11529  MALUCO! Uma coisa que eu não tenho coragem é e...         -1\n",
       "11530                            #MaisVoce   está linda           1\n",
       "11531                     Que orgulho de ti, ! #Encontro          1\n",
       "11532   Gente olha o bíceps desse padre #ConversaComBial          1\n",
       "\n",
       "[11533 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16a2bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_X(frases):\n",
    "    lista = []\n",
    "    \n",
    "    for frase in frases:\n",
    "        lista.append(frase)\n",
    "        \n",
    "    return lista\n",
    "\n",
    "def pre_Y(number):\n",
    "    lista = []\n",
    "    \n",
    "    for numb in number:\n",
    "        lista.append(numb)\n",
    "    \n",
    "    return lista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "719331ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_array(frases):\n",
    "    \n",
    "    vocab = []\n",
    "    palavras = []\n",
    "    for frase in frases:\n",
    "        \n",
    "        text_array = remove_user(frase)\n",
    "        text_array = Tokenize(text_array)\n",
    "        text_array = text_array.split(' ')\n",
    "        for i in range(len(text_array)):\n",
    "            vocab.append(text_array[i])\n",
    "    \n",
    "    \n",
    "        \n",
    "    return vocab\n",
    "\n",
    "def Tokenize(f):     ## Pre-processando a frase\n",
    "    \n",
    "    ## Colocando em minusculo\n",
    "    ## Retirando a pontuaçao\n",
    "    ## Retirando as StopWords\n",
    "    \n",
    "    f = f.lower().replace('\\n', '').replace('-','').replace('#','').replace('.','').replace(',','').replace('!','').replace('r\\n','').replace('  ','')\n",
    "    token = RegexpTokenizer(r\"\\w+\")\n",
    "    f = token.tokenize(f)\n",
    "    \n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    \n",
    "    new_word = [word for word in f if not word in stop_words]\n",
    "    \n",
    "    return ' '.join(new_word)\n",
    "\n",
    "def remove_user(frase):\n",
    "\n",
    "    return re.sub('@\\w+','',frase)\n",
    "\n",
    "def translater_phrases(frase):\n",
    "    translater = pten_pipeline(frase)\n",
    "    translater = str(translater).strip('[{}]')\n",
    "    translater = translater[19:]\n",
    "    translater = translater.strip(\"''\")\n",
    "    \n",
    "    return translater\n",
    "\n",
    "def translater_frases(frase):\n",
    "    text_hi = frase\n",
    "    translater = mt.translate(text_hi, source=dlt.lang.PORTUGUESE, target=dlt.lang.ENGLISH)\n",
    "    \n",
    "    return translater\n",
    "\n",
    "def new_classifier(frase):\n",
    "    input = tokenizerR.encode(frase, return_tensors=\"tf\")\n",
    "    output = modelR.predict(input)[0]\n",
    "    prediction = tf.nn.softmax(output, axis=1).numpy()\n",
    "    sentiment = np.argmax(prediction)\n",
    "    \n",
    "    return sentiment \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b0fb0bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tweet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Tweet \u001b[38;5;241m=\u001b[39m \u001b[43mTweet\u001b[49m\u001b[38;5;241m.\u001b[39mapply(remove_user)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Tweet' is not defined"
     ]
    }
   ],
   "source": [
    "Tweet = Tweet.apply(remove_user)\n",
    "# Tweet_preprocessed = Tweet.apply(Tokenize)\n",
    "\n",
    "# count_vect = CountVectorizer()\n",
    "# X_train = count_vect.fit_transform(Tweet_preprocessed)\n",
    "\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_train_transform = tfidf_transformer.fit_transform(X_train) # Aplicando o TF-IDF\n",
    "\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X_train_transform, polarity, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f1ef5986",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_in_English = pd.DataFrame(data = {'tweets_original': df_portuguese['text'][:20], 'tweets_translater_unicamp': df_english['phrases'][:20],'tweets_translater_face': df_portuguese['text'][:20].apply(translater_frases)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8aec7626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_original</th>\n",
       "      <th>tweets_translater_unicamp</th>\n",
       "      <th>tweets_translater_face</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Que coisa linda! O Programa #encontro estava m...</td>\n",
       "      <td>The #encontro Program was showing a family tha...</td>\n",
       "      <td>What a beautiful thing! The #touch program was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Por mais #Encontro com as Irmãs Galvão, adorei...</td>\n",
       "      <td>I loved them.</td>\n",
       "      <td>For more I met with the Galvan Sisters, I love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr. CATRA  lançando sua nova música PPK CHORA ...</td>\n",
       "      <td>CATRA launching its new song PPK CHORA no k</td>\n",
       "      <td>Mr. CATRA releases his new song PPK CHORA on k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quem viu aquela lutadora modela barbuda tatuad...</td>\n",
       "      <td>#MasterChefBR</td>\n",
       "      <td>Who saw that fighter model tattooed? #MasterCh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tô passada com esse cara.... quanta merda pode...</td>\n",
       "      <td>I'm handled with this guy.... how mu\"</td>\n",
       "      <td>How much shit can come out of someone’s mouth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cibele arrasou, humilhou!! #VideoShowAoVivo</td>\n",
       "      <td>#VideoShowAoVideo</td>\n",
       "      <td>The cave has broken, humiliated!! #VideoShowAo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Em Minas sacolé é chup chup!  #videoshowaovivo</td>\n",
       "      <td>In Minas sacolé is chup chup! #videoshowaovivo</td>\n",
       "      <td>In Minas sacolé is chup chup! #videohowaovivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Meu prato MasterChef de sardinha enlatada seri...</td>\n",
       "      <td>My dish MasterChef of sauced sardine would be ...</td>\n",
       "      <td>My MasterChef dish of enlated sardine would be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Esse japa não entendi porra nenhuma de orquíde...</td>\n",
       "      <td>This is not catleya Walkiriana, it is a Nobili...</td>\n",
       "      <td>This japa I didn't understand any of orchids. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A Cearamirinense mais famosa do Brasil no #Ede...</td>\n",
       "      <td>The most famous Cearamirinense in Brazil in #E...</td>\n",
       "      <td>The most famous Cearamirinense in Brazil at #E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nào sei vocês, mas quero  no #powercoupleBrasi...</td>\n",
       "      <td>Even in #MasterChefBR it's good, I want to\"</td>\n",
       "      <td>I know you, but I want to #powercoupleBrasil w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tem q passar essa entrevista em telões nas pra...</td>\n",
       "      <td>It is important to pass this interview on squa...</td>\n",
       "      <td>It has q to spend this interview on telons on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Estou todo derretido com o amor do Serginho e ...</td>\n",
       "      <td>I am all melted with the love of Serginho and ...</td>\n",
       "      <td>I'm all overwhelmed with the love of Serginho ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fatima Bernardes sobre o sotaque hahaha coerên...</td>\n",
       "      <td>Fatima Bernardes on the accent hahahahahahahah...</td>\n",
       "      <td>Fatima Bernardes on the accent hahaha professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Augusto Cury no #ConversaComBial IMPERDÍVEL!!!</td>\n",
       "      <td>Augusto Cury in #IMPERDIBLE ConversaComBial!!!</td>\n",
       "      <td>August Cury on #ConversaComBial IMPERDIBLE!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>#VideoShowAoVivo Sophia super sensual com essa...</td>\n",
       "      <td>The women's lifestyle is very sensual with thi...</td>\n",
       "      <td>#VideoShowAoVivo Sophia super sensual with thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Caraaaaaa não dormi ainda por causa desse cara...</td>\n",
       "      <td>Father Fábio de Melo ❤️ how much wisdom!!! #</td>\n",
       "      <td>I'm not sure I'm going to do it, I'm going to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Depois eu vou assistir, espero que ela cante a...</td>\n",
       "      <td>After I'm watching, I hope she will get the new\"</td>\n",
       "      <td>Then I'm going to watch, I hope she's singing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ai mds é agora #MasterChefBR</td>\n",
       "      <td>Ai mds is now #MasterChefBR</td>\n",
       "      <td>AI is now #MasterChefBR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Aí vc fica até 01h00 assistindo #MasterChefBR ...</td>\n",
       "      <td>Then you stay for up to 01:00 a.m. watching #Ma</td>\n",
       "      <td>Here you stay until 1h00 watching #MasterChefB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      tweets_original  \\\n",
       "0   Que coisa linda! O Programa #encontro estava m...   \n",
       "1   Por mais #Encontro com as Irmãs Galvão, adorei...   \n",
       "2   Mr. CATRA  lançando sua nova música PPK CHORA ...   \n",
       "3   quem viu aquela lutadora modela barbuda tatuad...   \n",
       "4   Tô passada com esse cara.... quanta merda pode...   \n",
       "5         Cibele arrasou, humilhou!! #VideoShowAoVivo   \n",
       "6      Em Minas sacolé é chup chup!  #videoshowaovivo   \n",
       "7   Meu prato MasterChef de sardinha enlatada seri...   \n",
       "8   Esse japa não entendi porra nenhuma de orquíde...   \n",
       "9   A Cearamirinense mais famosa do Brasil no #Ede...   \n",
       "10  nào sei vocês, mas quero  no #powercoupleBrasi...   \n",
       "11  Tem q passar essa entrevista em telões nas pra...   \n",
       "12  Estou todo derretido com o amor do Serginho e ...   \n",
       "13  Fatima Bernardes sobre o sotaque hahaha coerên...   \n",
       "14     Augusto Cury no #ConversaComBial IMPERDÍVEL!!!   \n",
       "15  #VideoShowAoVivo Sophia super sensual com essa...   \n",
       "16  Caraaaaaa não dormi ainda por causa desse cara...   \n",
       "17  Depois eu vou assistir, espero que ela cante a...   \n",
       "18                       ai mds é agora #MasterChefBR   \n",
       "19  Aí vc fica até 01h00 assistindo #MasterChefBR ...   \n",
       "\n",
       "                            tweets_translater_unicamp  \\\n",
       "0   The #encontro Program was showing a family tha...   \n",
       "1                                       I loved them.   \n",
       "2         CATRA launching its new song PPK CHORA no k   \n",
       "3                                       #MasterChefBR   \n",
       "4               I'm handled with this guy.... how mu\"   \n",
       "5                                   #VideoShowAoVideo   \n",
       "6      In Minas sacolé is chup chup! #videoshowaovivo   \n",
       "7   My dish MasterChef of sauced sardine would be ...   \n",
       "8   This is not catleya Walkiriana, it is a Nobili...   \n",
       "9   The most famous Cearamirinense in Brazil in #E...   \n",
       "10        Even in #MasterChefBR it's good, I want to\"   \n",
       "11  It is important to pass this interview on squa...   \n",
       "12  I am all melted with the love of Serginho and ...   \n",
       "13  Fatima Bernardes on the accent hahahahahahahah...   \n",
       "14     Augusto Cury in #IMPERDIBLE ConversaComBial!!!   \n",
       "15  The women's lifestyle is very sensual with thi...   \n",
       "16       Father Fábio de Melo ❤️ how much wisdom!!! #   \n",
       "17   After I'm watching, I hope she will get the new\"   \n",
       "18                        Ai mds is now #MasterChefBR   \n",
       "19    Then you stay for up to 01:00 a.m. watching #Ma   \n",
       "\n",
       "                               tweets_translater_face  \n",
       "0   What a beautiful thing! The #touch program was...  \n",
       "1   For more I met with the Galvan Sisters, I love...  \n",
       "2   Mr. CATRA releases his new song PPK CHORA on k...  \n",
       "3   Who saw that fighter model tattooed? #MasterCh...  \n",
       "4   How much shit can come out of someone’s mouth ...  \n",
       "5   The cave has broken, humiliated!! #VideoShowAo...  \n",
       "6       In Minas sacolé is chup chup! #videohowaovivo  \n",
       "7   My MasterChef dish of enlated sardine would be...  \n",
       "8   This japa I didn't understand any of orchids. ...  \n",
       "9   The most famous Cearamirinense in Brazil at #E...  \n",
       "10  I know you, but I want to #powercoupleBrasil w...  \n",
       "11  It has q to spend this interview on telons on ...  \n",
       "12  I'm all overwhelmed with the love of Serginho ...  \n",
       "13  Fatima Bernardes on the accent hahaha professi...  \n",
       "14      August Cury on #ConversaComBial IMPERDIBLE!!!  \n",
       "15  #VideoShowAoVivo Sophia super sensual with thi...  \n",
       "16  I'm not sure I'm going to do it, I'm going to ...  \n",
       "17  Then I'm going to watch, I hope she's singing ...  \n",
       "18                            AI is now #MasterChefBR  \n",
       "19  Here you stay until 1h00 watching #MasterChefB...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweets_in_English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1fd9cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificacoes = pd.DataFrame(data = {'origem_portugues': polarity[:20], 'classificação_uni': Tweets_in_English['tweets_translater_unicamp'].apply(classifier)[:20],'classificação_rabin_uni': Tweets_in_English['tweets_translater_unicamp'].apply(new_classifier), 'classificação_uni_face':Tweets_in_English['tweets_translater_face'].apply(classifier)[:20], 'classificação_rabin_face':Tweets_in_English['tweets_translater_face'].apply(new_classifier)[:20]  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ea0eb708",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificacoes['classificação_uni'] = classificacoes['classificação_uni'].apply(lambda x: x[0]['label'])\n",
    "classificacoes['classificação_uni_face'] = classificacoes['classificação_uni_face'].apply(lambda x: x[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a7da1f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificacoes['classificação_uni'] = classificacoes['classificação_uni'].replace('POSITIVE', 1).replace('NEGATIVE',-1)\n",
    "classificacoes['classificação_uni_face'] = classificacoes['classificação_uni_face'].replace('POSITIVE', 1).replace('NEGATIVE',-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1b2284de",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificacoes['classificação_rabin_uni'] = classificacoes['classificação_rabin_uni'].replace(0, -1).replace(1,0).replace(2,1)\n",
    "classificacoes['classificação_rabin_face'] = classificacoes['classificação_rabin_face'].replace(0, -1).replace(1,0).replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3705835d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_original</th>\n",
       "      <th>tweets_translater_unicamp</th>\n",
       "      <th>tweets_translater_face</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Que coisa linda! O Programa #encontro estava m...</td>\n",
       "      <td>The #encontro Program was showing a family tha...</td>\n",
       "      <td>What a beautiful thing! The #touch program was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Por mais #Encontro com as Irmãs Galvão, adorei...</td>\n",
       "      <td>I loved them.</td>\n",
       "      <td>For more I met with the Galvan Sisters, I love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr. CATRA  lançando sua nova música PPK CHORA ...</td>\n",
       "      <td>CATRA launching its new song PPK CHORA no k</td>\n",
       "      <td>Mr. CATRA releases his new song PPK CHORA on k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quem viu aquela lutadora modela barbuda tatuad...</td>\n",
       "      <td>#MasterChefBR</td>\n",
       "      <td>Who saw that fighter model tattooed? #MasterCh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tô passada com esse cara.... quanta merda pode...</td>\n",
       "      <td>I'm handled with this guy.... how mu\"</td>\n",
       "      <td>How much shit can come out of someone’s mouth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cibele arrasou, humilhou!! #VideoShowAoVivo</td>\n",
       "      <td>#VideoShowAoVideo</td>\n",
       "      <td>The cave has broken, humiliated!! #VideoShowAo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Em Minas sacolé é chup chup!  #videoshowaovivo</td>\n",
       "      <td>In Minas sacolé is chup chup! #videoshowaovivo</td>\n",
       "      <td>In Minas sacolé is chup chup! #videohowaovivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Meu prato MasterChef de sardinha enlatada seri...</td>\n",
       "      <td>My dish MasterChef of sauced sardine would be ...</td>\n",
       "      <td>My MasterChef dish of enlated sardine would be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Esse japa não entendi porra nenhuma de orquíde...</td>\n",
       "      <td>This is not catleya Walkiriana, it is a Nobili...</td>\n",
       "      <td>This japa I didn't understand any of orchids. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A Cearamirinense mais famosa do Brasil no #Ede...</td>\n",
       "      <td>The most famous Cearamirinense in Brazil in #E...</td>\n",
       "      <td>The most famous Cearamirinense in Brazil at #E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nào sei vocês, mas quero  no #powercoupleBrasi...</td>\n",
       "      <td>Even in #MasterChefBR it's good, I want to\"</td>\n",
       "      <td>I know you, but I want to #powercoupleBrasil w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tem q passar essa entrevista em telões nas pra...</td>\n",
       "      <td>It is important to pass this interview on squa...</td>\n",
       "      <td>It has q to spend this interview on telons on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Estou todo derretido com o amor do Serginho e ...</td>\n",
       "      <td>I am all melted with the love of Serginho and ...</td>\n",
       "      <td>I'm all overwhelmed with the love of Serginho ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fatima Bernardes sobre o sotaque hahaha coerên...</td>\n",
       "      <td>Fatima Bernardes on the accent hahahahahahahah...</td>\n",
       "      <td>Fatima Bernardes on the accent hahaha professi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Augusto Cury no #ConversaComBial IMPERDÍVEL!!!</td>\n",
       "      <td>Augusto Cury in #IMPERDIBLE ConversaComBial!!!</td>\n",
       "      <td>August Cury on #ConversaComBial IMPERDIBLE!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>#VideoShowAoVivo Sophia super sensual com essa...</td>\n",
       "      <td>The women's lifestyle is very sensual with thi...</td>\n",
       "      <td>#VideoShowAoVivo Sophia super sensual with thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Caraaaaaa não dormi ainda por causa desse cara...</td>\n",
       "      <td>Father Fábio de Melo ❤️ how much wisdom!!! #</td>\n",
       "      <td>I'm not sure I'm going to do it, I'm going to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Depois eu vou assistir, espero que ela cante a...</td>\n",
       "      <td>After I'm watching, I hope she will get the new\"</td>\n",
       "      <td>Then I'm going to watch, I hope she's singing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ai mds é agora #MasterChefBR</td>\n",
       "      <td>Ai mds is now #MasterChefBR</td>\n",
       "      <td>AI is now #MasterChefBR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Aí vc fica até 01h00 assistindo #MasterChefBR ...</td>\n",
       "      <td>Then you stay for up to 01:00 a.m. watching #Ma</td>\n",
       "      <td>Here you stay until 1h00 watching #MasterChefB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      tweets_original  \\\n",
       "0   Que coisa linda! O Programa #encontro estava m...   \n",
       "1   Por mais #Encontro com as Irmãs Galvão, adorei...   \n",
       "2   Mr. CATRA  lançando sua nova música PPK CHORA ...   \n",
       "3   quem viu aquela lutadora modela barbuda tatuad...   \n",
       "4   Tô passada com esse cara.... quanta merda pode...   \n",
       "5         Cibele arrasou, humilhou!! #VideoShowAoVivo   \n",
       "6      Em Minas sacolé é chup chup!  #videoshowaovivo   \n",
       "7   Meu prato MasterChef de sardinha enlatada seri...   \n",
       "8   Esse japa não entendi porra nenhuma de orquíde...   \n",
       "9   A Cearamirinense mais famosa do Brasil no #Ede...   \n",
       "10  nào sei vocês, mas quero  no #powercoupleBrasi...   \n",
       "11  Tem q passar essa entrevista em telões nas pra...   \n",
       "12  Estou todo derretido com o amor do Serginho e ...   \n",
       "13  Fatima Bernardes sobre o sotaque hahaha coerên...   \n",
       "14     Augusto Cury no #ConversaComBial IMPERDÍVEL!!!   \n",
       "15  #VideoShowAoVivo Sophia super sensual com essa...   \n",
       "16  Caraaaaaa não dormi ainda por causa desse cara...   \n",
       "17  Depois eu vou assistir, espero que ela cante a...   \n",
       "18                       ai mds é agora #MasterChefBR   \n",
       "19  Aí vc fica até 01h00 assistindo #MasterChefBR ...   \n",
       "\n",
       "                            tweets_translater_unicamp  \\\n",
       "0   The #encontro Program was showing a family tha...   \n",
       "1                                       I loved them.   \n",
       "2         CATRA launching its new song PPK CHORA no k   \n",
       "3                                       #MasterChefBR   \n",
       "4               I'm handled with this guy.... how mu\"   \n",
       "5                                   #VideoShowAoVideo   \n",
       "6      In Minas sacolé is chup chup! #videoshowaovivo   \n",
       "7   My dish MasterChef of sauced sardine would be ...   \n",
       "8   This is not catleya Walkiriana, it is a Nobili...   \n",
       "9   The most famous Cearamirinense in Brazil in #E...   \n",
       "10        Even in #MasterChefBR it's good, I want to\"   \n",
       "11  It is important to pass this interview on squa...   \n",
       "12  I am all melted with the love of Serginho and ...   \n",
       "13  Fatima Bernardes on the accent hahahahahahahah...   \n",
       "14     Augusto Cury in #IMPERDIBLE ConversaComBial!!!   \n",
       "15  The women's lifestyle is very sensual with thi...   \n",
       "16       Father Fábio de Melo ❤️ how much wisdom!!! #   \n",
       "17   After I'm watching, I hope she will get the new\"   \n",
       "18                        Ai mds is now #MasterChefBR   \n",
       "19    Then you stay for up to 01:00 a.m. watching #Ma   \n",
       "\n",
       "                               tweets_translater_face  \n",
       "0   What a beautiful thing! The #touch program was...  \n",
       "1   For more I met with the Galvan Sisters, I love...  \n",
       "2   Mr. CATRA releases his new song PPK CHORA on k...  \n",
       "3   Who saw that fighter model tattooed? #MasterCh...  \n",
       "4   How much shit can come out of someone’s mouth ...  \n",
       "5   The cave has broken, humiliated!! #VideoShowAo...  \n",
       "6       In Minas sacolé is chup chup! #videohowaovivo  \n",
       "7   My MasterChef dish of enlated sardine would be...  \n",
       "8   This japa I didn't understand any of orchids. ...  \n",
       "9   The most famous Cearamirinense in Brazil at #E...  \n",
       "10  I know you, but I want to #powercoupleBrasil w...  \n",
       "11  It has q to spend this interview on telons on ...  \n",
       "12  I'm all overwhelmed with the love of Serginho ...  \n",
       "13  Fatima Bernardes on the accent hahaha professi...  \n",
       "14      August Cury on #ConversaComBial IMPERDIBLE!!!  \n",
       "15  #VideoShowAoVivo Sophia super sensual with thi...  \n",
       "16  I'm not sure I'm going to do it, I'm going to ...  \n",
       "17  Then I'm going to watch, I hope she's singing ...  \n",
       "18                            AI is now #MasterChefBR  \n",
       "19  Here you stay until 1h00 watching #MasterChefB...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweets_in_English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2a0bfc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origem_portugues</th>\n",
       "      <th>classificação_uni</th>\n",
       "      <th>classificação_rabin_uni</th>\n",
       "      <th>classificação_uni_face</th>\n",
       "      <th>classificação_rabin_face</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    origem_portugues  classificação_uni  classificação_rabin_uni  \\\n",
       "0                  1                 -1                        0   \n",
       "1                  1                  1                        1   \n",
       "2                  1                  1                        0   \n",
       "3                  0                  1                        0   \n",
       "4                 -1                 -1                        0   \n",
       "5                  1                 -1                        0   \n",
       "6                  0                 -1                        0   \n",
       "7                  0                 -1                        0   \n",
       "8                 -1                 -1                        0   \n",
       "9                  1                  1                        1   \n",
       "10                 1                  1                        1   \n",
       "11                 1                 -1                        0   \n",
       "12                 1                  1                        1   \n",
       "13                 0                 -1                        0   \n",
       "14                 1                 -1                        0   \n",
       "15                 1                  1                        1   \n",
       "16                 1                  1                        1   \n",
       "17                 1                  1                        0   \n",
       "18                 1                  1                        0   \n",
       "19                -1                 -1                        0   \n",
       "\n",
       "    classificação_uni_face  classificação_rabin_face  \n",
       "0                        1                         1  \n",
       "1                        1                         1  \n",
       "2                       -1                         1  \n",
       "3                       -1                         0  \n",
       "4                       -1                        -1  \n",
       "5                       -1                        -1  \n",
       "6                       -1                         0  \n",
       "7                       -1                         0  \n",
       "8                       -1                        -1  \n",
       "9                        1                         1  \n",
       "10                       1                         1  \n",
       "11                      -1                         0  \n",
       "12                       1                         1  \n",
       "13                      -1                         1  \n",
       "14                      -1                         1  \n",
       "15                       1                         1  \n",
       "16                      -1                         0  \n",
       "17                       1                         0  \n",
       "18                       1                         0  \n",
       "19                      -1                         0  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655aa45e",
   "metadata": {},
   "source": [
    "## Acuracia da origem com classificador do huggingface e traduzido com o tradutor da unicamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fafae750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soma = 0\n",
    "for i in range (len(classificacoes)):\n",
    "    if(int(classificacoes['origem_portugues'][i]) == int(classificacoes['classificação_uni'][i])):\n",
    "        soma+=1\n",
    "\n",
    "soma/len(classificacoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680efd9",
   "metadata": {},
   "source": [
    "## Acuracia da origem com classificador do rabin e traduzido com o tradutor da unicamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c28cf363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soma = 0\n",
    "for i in range (len(classificacoes)):\n",
    "    if(int(classificacoes['origem_portugues'][i]) == int(classificacoes['classificação_rabin_uni'][i])):\n",
    "        soma+=1\n",
    "\n",
    "soma/len(classificacoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5041356",
   "metadata": {},
   "source": [
    "## Acuracia da origem com classificador do huggingface e traduzido com o tradutor da m2m100 ou face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "483493dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soma = 0\n",
    "for i in range (len(classificacoes)):\n",
    "    if(int(classificacoes['origem_portugues'][i]) == int(classificacoes['classificação_uni_face'][i])):\n",
    "        soma+=1\n",
    "\n",
    "soma/len(classificacoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ba6a2a",
   "metadata": {},
   "source": [
    "## Acuracia da origem com classificador do rabin e traduzido com o tradutor da m2m100 ou face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "76830d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soma = 0\n",
    "for i in range (len(classificacoes)):\n",
    "    if(int(classificacoes['origem_portugues'][i]) == int(classificacoes['classificação_rabin_face'][i])):\n",
    "        soma+=1\n",
    "\n",
    "soma/len(classificacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ec282b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
